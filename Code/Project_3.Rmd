---
title: "Project 3 - Data Science Skills"
author:
 - Brandon Cunningham^[cunningham.brandon3@gmail.com]
 - Rashad Long^[RDLong718@gmail.com]
 - Biyag Dukuray^[biyag15@gmail.com]
 - Nikoleta Emanouilidi^[nicolettaemm@gmail.com]
 - Markella Gialouris^[markella.gialouris07@spsmail.cuny.edu]
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, message = FALSE, warning = FALSE)
library(readr)
library(dplyr)
library(tidyverse)
library(knitr)
library(magick)
library(here) # For making the script run without a wd
library(magrittr) # For piping the logo to the plot
library(gtable)
library(grid)
library(png)
```

## Introduction
This project aims to establish a quantitative assessment of the relative value of specific skills for data science professionals. We will achieve this by analyzing data extracted from job postings on relevant job boards. The analysis will focus on two key aspects of data scientist job postings: advertised salary and the frequency of specific skills mentioned in the job descriptions. By correlating these factors, we can develop a proxy measure to compare the relative value of various skills sought after in the data science job market.


```{r}
Postings_url <- 'https://media.githubusercontent.com/media/RDLong718/data607-project3/main/Data/job_postings.csv'
Postings_raw <- readr::read_csv(Postings_url)
Salries_url <- 'https://media.githubusercontent.com/media/RDLong718/data607-project3/main/Data/job_details/salaries.csv'
Salaries_raw <- readr::read_csv(Salries_url)

```

```{r}
linkedin_postings <- Postings_raw[c('job_id', 'title', 'description')]
linkedin_salaries <- Postings_raw[c('job_id', 'max_salary', 'min_salary', 'med_salary', 'pay_period')]
```

```{r}
linkedin_salaries$med_salary <- (linkedin_salaries$max_salary + linkedin_salaries$min_salary)/2
linkedin_salaries$med_salary[linkedin_salaries$pay_period == 'HOURLY' & !is.na(linkedin_salaries$pay_period)] <- linkedin_salaries$med_salary[linkedin_salaries$pay_period == 'HOURLY' & !is.na(linkedin_salaries$pay_period)] * 40 * 52
linkedin_salaries$med_salary[linkedin_salaries$med_salary < 1000 & !is.na(linkedin_salaries$med_salary)] <- linkedin_salaries$med_salary[linkedin_salaries$med_salary < 1000] * 1000
salaries_clean <- linkedin_salaries[c('job_id', 'med_salary')]
#top_5 <- head(salaries_clean, 5)
#kable(top_5)
```

```{r}
data_science_postings <- linkedin_postings[grepl("data science|data scientist", linkedin_postings$title, ignore.case = TRUE), ]
linkedin_clean <- merge(data_science_postings, salaries_clean, by = 'job_id', all.x=TRUE)
linkedin_clean$med_salary[is.na(linkedin_clean$med_salary)] <- median(linkedin_clean$med_salary, na.rm=TRUE)
#top_5 <- head(linkedin_clean, 5)
#kable(top_5)
```
After cleaning up the data sets we now have a combined data set with the job titles, descriptions, and median expected salaries for each position.

Here's a template for searching for words/terms:
#linkedin_clean$colName <- ifelse(grepl('term1|term2|term3', linkedin_clean$description, ignore.case = TRUE), 1,0)
#linkedin_clean$ <- ifelse(grepl('', linkedin_clean$description, ignore.case = TRUE), 1,0)
```{r}
linkedin_clean$Programming <- ifelse(grepl('python| r | r/|/r/|/r|\\(r,| r,| r.|c\\+\\+|sql', linkedin_clean$description, ignore.case = TRUE), 1,0)
linkedin_clean$Machine_Learning <- ifelse(grepl('machine learning| ml|algorithms|scikit learn|transformers|language model', linkedin_clean$description, ignore.case = TRUE), 1,0)
linkedin_clean$Statistics <- ifelse(grepl('data analysis|data analytics|statistical analysis|data-driven analysis', linkedin_clean$description, ignore.case = TRUE), 1,0)
linkedin_clean$Cloud_Computing <- ifelse(grepl('cloud computing| aws|\\(aws|/aws|amazon web|google cloud', linkedin_clean$description, ignore.case = TRUE), 1,0)
linkedin_clean$Visualization <- ifelse(grepl('visualization|presentation', linkedin_clean$description, ignore.case = TRUE), 1,0)
linkedin_clean$Collaboration <- ifelse(grepl('team work|with a team|collaborat|scrum team|agile team', linkedin_clean$description, ignore.case = TRUE), 1,0)
linkedin_clean$Detail_Orientation <- ifelse(grepl("detail oriented|meticulous|precise|thorough|attention to detail|accuracy", linkedin_clean$description, ignore.case = TRUE), 1, 0)
linkedin_clean$Critical_Thinking <- ifelse(grepl( "critical thinking|problem solving|analytical skills|logical analysis|creative problem solving|critical reasoning", linkedin_clean$description, ignore.case = TRUE), 1, 0)
linkedin_clean$Communication_Skills <- ifelse(grepl("written and verbal communication|effective communication|articulate|persuasive|clear communication|concise communication|communication skills", linkedin_clean$description, ignore.case = TRUE), 1, 0)
linkedin_clean$Predictive_Analytics <- ifelse(grepl("forecasting|predictive modeling|predictive analytics|statistical forecasting|data forecasting|forecasting techniques", linkedin_clean$description, ignore.case = TRUE), 1, 0)
```

### Analysis

We will now analyze the data to determine the top 5 skills that are most frequently mentioned in the job postings.


```{r}
# make a vector of the column skill names in linkedin_clean
skill_names <- colnames(linkedin_clean)[5:ncol(linkedin_clean)]

# Make a new data frame with the total number of times each skill is mentioned top 5
top5_skills <- linkedin_clean |>
  select(skill_names) |>
  summarise_all(sum) |>
  gather(skill, total) |>
  arrange(desc(total)) |>
  head(5)

top5_skills
```



```{r include=FALSE}
# Download PNG files of the LinkedIn logo
download.file(
  "https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/900px-LinkedIn_logo_initials.png",
  mode = "wb",
  destfile = here("linkedin_logo.png")
)
```

We see that the top 5 skills are: Programming, Collaboration, Statistics, Machine Learning, and Visualization. We will now create a bar plot to visualize the top 5 skills and their frequency in the job postings.


```{r}

# Position the logo via rasterGrob.
get_png <-
  function(filename,
           x = unit(0.5, "npc"),
           y = unit(0.5, "npc"),
           width = NULL,
           height = NULL,
           gp = grid::gpar()) {
    grid::rasterGrob(
      png::readPNG(filename),
      interpolate = TRUE,
      x = x,
      y = y,
      width = width,
      height = height,
      gp = gp
    )
  }

width = 3

# Save the logo as a grob
logo <-
  get_png(
    here("linkedin_logo.png"),
    x = unit(1.31, "npc") - unit(width / 2, "lines"),
    y = unit(0, "lines"),
    width = unit(width, "lines")
  )

# Plot the Top 5 skills
top5_skills_plot <- function(x, width = 3) {
  ggplot(top5_skills, aes(
    x = reorder(skill, total),
    y = total,
    fill = skill
  )) +
    geom_col() +
    coord_cartesian(clip = "off") +
    theme(
      axis.text.x = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks = element_blank()
    ) +
    geom_text(aes(label = total), vjust = -0.2) +
    labs(x = "", y = "", title = "Top 5 Skills on LinkedIn for Data Scientists")
}

top5_skills_plot(top5_skills) + scale_fill_manual(values = c("#caf0f8", "#00b4d8", "#03045e", "#0077b6", "#90e0ef")) + annotation_custom(logo)
```
