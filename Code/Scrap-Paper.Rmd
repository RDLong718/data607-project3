---
title: "Project 3"
author: "Brandon Cunningham, 
Rashad Long, 
Biyag Dukuray, 
Nikoleta Emanouilidi, 
Markella Gialouris"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, message = FALSE, warning = FALSE)
library(readr)
library(dplyr)
library(tidyverse)
library(knitr)
library(magick)
library(here) # For making the script run without a wd
library(magrittr) # For piping the logo to the plot
library(gtable)
```

## Introduction
In this project we will be attempting to figure out the value of certain skills for a data scientist to have. Our method for determining value revolves around grabbing job postings for data scientists from job board websites and obtaining the expected salary of each listing and the skills mentioned in its description in conjunction with the pure number of times a skill is mentioned to come up with a proxy measure for its relative value compared to other skills.


```{r}
Postings_url <- 'https://media.githubusercontent.com/media/RDLong718/data607-project3/main/Data/job_postings.csv'
Postings_raw <- readr::read_csv(Postings_url)
Salries_url <- 'https://media.githubusercontent.com/media/RDLong718/data607-project3/main/Data/job_details/salaries.csv'
Salaries_raw <- readr::read_csv(Salries_url)
```

```{r}
linkedin_postings <- Postings_raw[c('job_id', 'title', 'description')]
linkedin_salaries <- Postings_raw[c('job_id', 'max_salary', 'min_salary', 'med_salary', 'pay_period')]
```

```{r}
linkedin_salaries$med_salary <- (linkedin_salaries$max_salary + linkedin_salaries$min_salary)/2
linkedin_salaries$med_salary[linkedin_salaries$pay_period == 'HOURLY' & !is.na(linkedin_salaries$pay_period)] <- linkedin_salaries$med_salary[linkedin_salaries$pay_period == 'HOURLY' & !is.na(linkedin_salaries$pay_period)] * 40 * 52
linkedin_salaries$med_salary[linkedin_salaries$med_salary < 1000 & !is.na(linkedin_salaries$med_salary)] <- linkedin_salaries$med_salary[linkedin_salaries$med_salary < 1000] * 1000
salaries_clean <- linkedin_salaries[c('job_id', 'med_salary')]
#top_5 <- head(salaries_clean, 5)
#kable(top_5)
```

```{r}
data_science_postings <- linkedin_postings[grepl("data science|data scientist", linkedin_postings$title, ignore.case = TRUE), ]
linkedin_clean <- merge(data_science_postings, salaries_clean, by = 'job_id', all.x=TRUE)
linkedin_clean$med_salary[is.na(linkedin_clean$med_salary)] <- median(linkedin_clean$med_salary, na.rm=TRUE)
#top_5 <- head(linkedin_clean, 5)
#kable(top_5)
```
After cleaning up the data sets we now have a combined data set with the job titles, descriptions, and median expected salaries for each position.

Here's a template for searching for words/terms:
#linkedin_clean$colName <- ifelse(grepl('term1|term2|term3', linkedin_clean$description, ignore.case = TRUE), 1,0)
#linkedin_clean$ <- ifelse(grepl('', linkedin_clean$description, ignore.case = TRUE), 1,0)
```{r}
linkedin_clean$Programming <- ifelse(grepl('python| r | r/|/r/|/r|\\(r,| r,| r.|c\\+\\+|sql', linkedin_clean$description, ignore.case = TRUE), 1,0)
linkedin_clean$Machine_Learning <- ifelse(grepl('machine learning| ml|algorithms|scikit learn|transformers|language model', linkedin_clean$description, ignore.case = TRUE), 1,0)
linkedin_clean$Stats <- ifelse(grepl('data analysis|data analytics|statistical analysis|data-driven analysis', linkedin_clean$description, ignore.case = TRUE), 1,0)
linkedin_clean$cloud_computing <- ifelse(grepl('cloud computing| aws|\\(aws|/aws|amazon web|google cloud', linkedin_clean$description, ignore.case = TRUE), 1,0)
linkedin_clean$visualization <- ifelse(grepl('visualization|presentation', linkedin_clean$description, ignore.case = TRUE), 1,0)
linkedin_clean$collaberation <- ifelse(grepl('team work|with a team|collaberat|scrum team|agile team', linkedin_clean$description, ignore.case = TRUE), 1,0)
```

```{r}

# make a vector of the column names in linkedin_clean
skill_names <- colnames(linkedin_clean)[5:ncol(linkedin_clean)]
skill_names

# make a new data frame with the skill names and the count of each skill
skills <- linkedin_clean %>%
  gather(key = "skill", value = "count", (all_of(skill_names))) |> 
  group_by(skill) |> 
  summarize(total = sum(count)) |> 
  arrange(desc(total))

skills <- 
  head(skills, 5)

# Dowload PNG files of the LinkedIn logo
download.file("https://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/LinkedIn_logo_initials.png/900px-LinkedIn_logo_initials.png", mode ="wb", destfile = here("linkedin_logo.png"))


# Position the logo via rasterGrab
get_png <- function(filename, x = unit(0.5, "npc"), y= unit(0.5, "npc"), 
                    width = NULL, height = NULL, gp = grid::gpar()) {
  grid::rasterGrob(png::readPNG(filename), interpolate = TRUE,
                   x = x, y = y, width = width, height = height, gp = gp)
}

width = 3

# Create the plot
l <- get_png(
  "linkedin_logo.png",
  x = unit(1, "npc") - unit(width / 2, "lines"),
  y = unit(-width, "lines"),
  width = unit(width, "lines")
)
# plot skills

skills_plot <- function(x, width = 3) {
  ggplot(skills, aes(
    x = reorder(skill, total),
    y = total,
    fill = skill
  )) +
    geom_col() +
    
    coord_cartesian(clip = "off") +
    
    theme(
      axis.text.x = element_text(
        face = "bold",
        color = "red",
        size = 8,
        angle = 45,
        vjust = .6,
        hjust = .6
      ),
      axis.text.y = element_text(
        face = "bold",
        color = "blue",
        size = 8,
        angle = 45
      )
    ) +
    labs(x = "Skill", y = "Count", title = "Top 5 Skills on LinkedIn")
}
skills_plot(skills) + annotation_custom(l)




```


